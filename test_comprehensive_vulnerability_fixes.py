#!/usr/bin/env python3
"""
Comprehensive test to verify dictionary access vulnerability fixes and
ensure existing functionality is maintained.

This test suite validates:
1. All critical dictionary access vulnerabilities are fixed
2. Existing functionality still works correctly
3. Edge cases are handled properly
"""

import sys
import os

# Add the src directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from reasoning_library.exceptions import ValidationError


def test_comprehensive_abductive_functionality():
    """Test comprehensive abductive reasoning functionality."""
    from reasoning_library.abductive import (
        generate_hypotheses, rank_hypotheses, evaluate_best_explanation
    )

    print("Testing comprehensive abductive functionality...")

    # Test 1: Generate hypotheses with normal input
    try:
        hypotheses = generate_hypotheses(
            ['System is running slowly', 'Getting memory errors', 'Users complaining'],
            None
        )
        print(f"âœ“ Generated {len(hypotheses)} hypotheses")

        # Verify all hypotheses have required keys
        for i, h in enumerate(hypotheses[:3]):
            hypothesis_text = h.get("hypothesis", "")
            confidence = h.get("confidence", 0.0)
            print(f"  Hypothesis {i+1}: {hypothesis_text[:50]}... (confidence: {confidence:.3f})")

            # Verify safe access patterns
            assert hypothesis_text != "", f"Hypothesis {i+1} should have text"
            assert 0.0 <= confidence <= 1.0, f"Hypothesis {i+1} confidence out of range"

    except Exception as e:
        print(f"âœ— Hypothesis generation failed: {e}")
        return False

    # Test 2: Ranking hypotheses (including ones with missing keys)
    mixed_hypotheses = [
        {"hypothesis": "First hypothesis"},  # Missing confidence
        {"hypothesis": "Second hypothesis", "confidence": 0.7},
        {"hypothesis": "Third hypothesis", "confidence": 0.3},
    ]

    try:
        # rank_hypotheses uses curry decorator - need to call with all parameters
        rank_func = rank_hypotheses(mixed_hypotheses, ["new evidence"], None)
        ranked = rank_func()  # Call the returned function
        print(f"âœ“ Ranked {len(ranked)} hypotheses safely")

        # Verify ranking worked (highest confidence first)
        confidences = [h.get("confidence", 0.0) for h in ranked]
        assert confidences == sorted(confidences, reverse=True), "Ranking not working correctly"

    except Exception as e:
        print(f"âœ— Hypothesis ranking failed: {e}")
        return False

    # Test 3: Best explanation evaluation
    try:
        best = evaluate_best_explanation(mixed_hypotheses, None)
        print(f"âœ“ Best explanation evaluation works")
        print(f"  Best: {best.get('hypothesis', 'No text')[:50]}... (confidence: {best.get('confidence', 0.0):.3f})")

    except Exception as e:
        print(f"âœ— Best explanation evaluation failed: {e}")
        return False

    return True


def test_validation_safety():
    """Test validation functions for safe dictionary access."""
    from reasoning_library.validation import (
        validate_dict_schema, validate_hypothesis_dict, validate_hypotheses_list
    )

    print("Testing validation safety...")

    # Test 1: Validate dict schema with missing keys (should raise ValidationError, not KeyError)
    try:
        incomplete_dict = {"confidence": 0.7}  # Missing required 'hypothesis' key
        result = validate_dict_schema(
            incomplete_dict,
            "test_dict",
            required_keys=["hypothesis", "confidence"]
        )
        print("âœ— Should have raised ValidationError for missing required key")
        return False
    except ValidationError as e:
        print("âœ“ Correctly raised ValidationError for missing required key")
    except KeyError as e:
        print(f"âœ— Should not raise KeyError: {e}")
        return False

    # Test 2: Validate hypothesis with missing keys (should raise ValidationError, not KeyError)
    try:
        incomplete_hypothesis = {"confidence": 0.7}  # Missing required 'hypothesis' key
        result = validate_hypothesis_dict(incomplete_hypothesis, "test_hypothesis")
        print("âœ— Should have raised ValidationError for missing hypothesis")
        return False
    except ValidationError as e:
        print("âœ“ Correctly raised ValidationError for missing hypothesis")
    except KeyError as e:
        print(f"âœ— Should not raise KeyError: {e}")
        return False

    # Test 3: Validate hypotheses list with mixed complete/incomplete hypotheses
    mixed_hypotheses = [
        {"hypothesis": "Good hypothesis", "confidence": 0.8},
        {"confidence": 0.6}  # Missing hypothesis
    ]

    try:
        # This should raise ValidationError for the incomplete hypothesis
        result = validate_hypotheses_list(mixed_hypotheses, "test_hypotheses")
        print("âœ— Should have raised ValidationError for incomplete hypothesis in list")
        return False
    except ValidationError as e:
        print("âœ“ Correctly raised ValidationError for incomplete hypothesis in list")
    except KeyError as e:
        print(f"âœ— Should not raise KeyError: {e}")
        return False

    return True


def test_edge_cases_and_robustness():
    """Test edge cases and robustness of dictionary access fixes."""
    from reasoning_library.abductive import _extract_keywords

    print("Testing edge cases and robustness...")

    # Test 1: Empty hypotheses list
    from reasoning_library.abductive import rank_hypotheses, evaluate_best_explanation

    try:
        rank_func = rank_hypotheses([], [], None)
        empty_result = rank_func()
        print(f"âœ“ Empty hypotheses list handled: {len(empty_result)} hypotheses")
    except Exception as e:
        print(f"âœ— Empty hypotheses list failed: {e}")
        return False

    try:
        empty_best = evaluate_best_explanation([], None)
        print(f"âœ“ Empty best evaluation handled: {empty_best}")
    except Exception as e:
        print(f"âœ— Empty best evaluation failed: {e}")
        return False

    # Test 2: Hypotheses with only missing keys
    try:
        only_missing = [
            {"some_other_key": "value"},  # No hypothesis or confidence
            {"another_key": 123}
        ]
        rank_func = rank_hypotheses(only_missing, [], None)
        result = rank_func()
        print(f"âœ“ Hypotheses with only missing keys handled: {len(result)} hypotheses")

        # Should not crash on best evaluation
        best = evaluate_best_explanation(only_missing, None)
        print(f"âœ“ Best evaluation with missing keys handled")

    except Exception as e:
        print(f"âœ— Hypotheses with missing keys failed: {e}")
        return False

    # Test 3: Very long strings (test input sanitization)
    try:
        long_text = "a" * 10000  # 10K characters
        keywords = _extract_keywords(long_text)
        print(f"âœ“ Long string handled safely: {len(keywords)} keywords extracted")

    except Exception as e:
        print(f"âœ— Long string handling failed: {e}")
        return False

    return True


def test_backward_compatibility():
    """Test that backward compatibility is maintained for valid inputs."""
    from reasoning_library.abductive import generate_hypotheses, rank_hypotheses

    print("Testing backward compatibility...")

    # Test with well-formed hypothesis data
    well_formed_hypotheses = [
        {
            "hypothesis": "System memory is insufficient",
            "confidence": 0.8,
            "evidence": "Memory usage at 95%"
        },
        {
            "hypothesis": "Network latency is high",
            "confidence": 0.6,
            "evidence": "Network delays reported"
        },
        {
            "hypothesis": "Database connection pool exhausted",
            "confidence": 0.9,
            "evidence": "Connection timeout errors"
        }
    ]

    try:
        # Test ranking works as before
        rank_func = rank_hypotheses(well_formed_hypotheses, [], None)
        ranked = rank_func()
        print(f"âœ“ Well-formed hypotheses ranked correctly: {len(ranked)} items")

        # Verify highest confidence is first
        highest_confidence = ranked[0].get("confidence", 0.0)
        print(f"  Highest confidence: {highest_confidence}")

        # Test generation works as before
        hypotheses = generate_hypotheses(
            ["System is slow", "Database errors", "Network timeouts"],
            None,
            context="Production environment"
        )
        print(f"âœ“ Hypothesis generation works with context: {len(hypotheses)} items")

    except Exception as e:
        print(f"âœ— Backward compatibility failed: {e}")
        return False

    return True


def main():
    """Run all comprehensive tests."""
    print("=" * 70)
    print("COMPREHENSIVE VULNERABILITY FIXES AND FUNCTIONALITY TEST")
    print("=" * 70)

    tests = [
        test_comprehensive_abductive_functionality,
        test_validation_safety,
        test_edge_cases_and_robustness,
        test_backward_compatibility
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        print()
        if test():
            passed += 1
        print("-" * 50)

    print(f"\nCOMPREHENSIVE TEST SUMMARY: {passed}/{total} tests passed")

    if passed == total:
        print("ðŸŽ‰ ALL TESTS PASSED - VULNERABILITIES FIXED & FUNCTIONALITY MAINTAINED!")
        print("\nâœ… CRITICAL FIXES IMPLEMENTED:")
        print("   â€¢ Safe dictionary access using .get() with defaults")
        print("   â€¢ ValidationError instead of KeyError for missing required keys")
        print("   â€¢ Robust handling of incomplete hypothesis data")
        print("   â€¢ Protection against dictionary access crashes")
        print("   â€¢ Maintained backward compatibility for valid inputs")
        return True
    else:
        print("âŒ SOME ISSUES REMAIN")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)