#!/usr/bin/env python3
"""
Test to identify the actual template injection vulnerability in _safe_hypothesis_template.

This focuses on the specific vulnerability: dangerous patterns are checked AFTER replacements,
which means new dangerous patterns can be created by the replacement process itself.
"""

import sys
import os

# Add the src directory to the path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from reasoning_library.abductive import _safe_hypothesis_template

def demonstrate_actual_vulnerability():
    """Demonstrate the actual vulnerability in the manual replacement approach."""

    print("üéØ DEMONSTRATING ACTUAL VULNERABILITY")
    print("=" * 50)

    print("""
VULNERABILITY ANALYSIS:
The _safe_hypothesis_template function has a critical flaw:

1. Sanitizes inputs (removes dangerous keywords)
2. Performs string replacements
3. THEN checks for dangerous patterns in FINAL result

The vulnerability is in step 3: replacements can create new dangerous patterns
that weren't in the original sanitized inputs.

Example Attack Vector:
- Input action: "test"
- Input component: "__import__" (gets sanitized to "")
- Input issue: "failure"
- Template: "The {action} on component{component} causes {issue}"

After sanitization: component becomes empty string
After replacement: "The test on component causes failure"
BUT if we manipulate it correctly, we can create dangerous patterns!
""")

    # Try to find an actual working exploit
    attack_vectors = [
        # Vector 1: Use sanitization removal to create new patterns
        {
            "name": "Sanitization Gap Exploit",
            "action": "test",
            "component": "__import__( 'os' )",  # This gets sanitized to "BLOCKED"
            "issue": "failure",
            "template": "The {action} on sys{component}.system causes {issue}",
            "expected": "Reconstruction might create 'sysBLOCKED.system'"
        },

        # Vector 2: Partial keyword reconstruction
        {
            "name": "Partial Keyword Reconstruction",
            "action": "test",
            "component": "im",  # Safe by itself
            "issue": "port os",  # Safe by itself
            "template": "The {action} on {component}{issue} causes failure",
            "expected": "Creates 'import os' across replacement boundary"
        },

        # Vector 3: Bracket manipulation
        {
            "name": "Bracket Manipulation",
            "action": "{",  # Gets sanitized but might leave something
            "component": "__import__('os')",
            "issue": "}",
            "template": "The {action}action{component}test{issue} causes failure",
            "expected": "Might create dangerous bracket patterns"
        },

        # Vector 4: Multi-step reconstruction
        {
            "name": "Multi-Step Reconstruction",
            "action": "sys",
            "component": "tem",
            "issue": "__import__('os')",
            "template": "The {action}{component}.{action} causes {issue}",
            "expected": "Creates 'system.sys' with dangerous import"
        },

        # Vector 5: Template concatenation attack
        {
            "name": "Template Concatenation Attack",
            "action": "${__import__('os')",
            "component": "}",
            "issue": "failure",
            "template": "The {action}{component} on system causes {issue}",
            "expected": "Creates ${__import__('os')} pattern"
        },

        # Vector 6: Encoding bypass through concatenation
        {
            "name": "Encoding Concatenation Bypass",
            "action": "\\x69\\x6d\\x70\\x6f\\x72\\x74",  # "import" in hex
            "component": " os",
            "issue": "failure",
            "template": "The {action}{component} system causes {issue}",
            "expected": "Might reconstruct 'import os'"
        }
    ]

    vulnerabilities_found = 0

    for i, attack in enumerate(attack_vectors, 1):
        print(f"\nüö® Attack {i}/{len(attack_vectors)}: {attack['name']}")
        print(f"   Strategy: {attack['expected']}")
        print(f"   Action: '{attack['action']}'")
        print(f"   Component: '{attack['component']}'")
        print(f"   Issue: '{attack['issue']}'")
        print(f"   Template: '{attack['template']}'")

        try:
            # Test step by step to see what happens
            from reasoning_library.sanitization import sanitize_for_concatenation

            safe_action = sanitize_for_concatenation(attack['action'])
            safe_component = sanitize_for_concatenation(attack['component'])
            safe_issue = sanitize_for_concatenation(attack['issue'])

            print(f"   üìù After sanitization:")
            print(f"      Action: '{safe_action}'")
            print(f"      Component: '{safe_component}'")
            print(f"      Issue: '{safe_issue}'")

            # Manual replacement simulation
            step1 = attack['template'].replace("{action}", safe_action)
            step2 = step1.replace("{component}", safe_component)
            step3 = step2.replace("{issue}", safe_issue)

            print(f"   üîÑ Manual replacement result: '{step3}'")

            # Test with actual function
            result = _safe_hypothesis_template(
                attack['action'],
                attack['component'],
                attack['issue'],
                attack['template']
            )

            print(f"   üì§ Actual function result: '{result}'")

            # Check for dangerous patterns
            critical_patterns = [
                '__import__',
                'system(',
                'exec(',
                'eval(',
                'subprocess',
                'popen',
                'import os',
                'os.system',
                '${',
                '%(',
                'getattr',
                'setattr'
            ]

            reconstruction_patterns = [
                'import',
                'system',
                'exec',
                'eval',
                'getattr',
                '__class',
                '__base'
            ]

            has_critical = any(pattern in result for pattern in critical_patterns)
            has_reconstruction = any(pattern in result for pattern in reconstruction_patterns)

            # Special check for reconstruction across boundaries
            if 'import' in result and 'os' in result and result.index('import') < result.index('os') and result.index('os') - result.index('import') < 10:
                has_reconstruction = True
                print("   üîç DETECTED: 'import os' pattern reconstruction!")

            if has_critical:
                print("   üö® VULNERABILITY CONFIRMED: Critical dangerous pattern found!")
                vulnerabilities_found += 1
            elif has_reconstruction:
                print("   ‚ö†Ô∏è  VULNERABILITY LIKELY: Dangerous keyword reconstruction detected!")
                vulnerabilities_found += 1
            else:
                print("   ‚úÖ No vulnerability detected")

        except Exception as e:
            print(f"   üí• Exception: {type(e).__name__}: {e}")
            if any(keyword in str(e).lower() for keyword in ['import', 'exec', 'eval', 'system']):
                print("   üö® VULNERABILITY: Exception contains dangerous keywords!")
                vulnerabilities_found += 1

    print(f"\nüìä VULNERABILITY SUMMARY")
    print("=" * 30)
    print(f"Attacks tested: {len(attack_vectors)}")
    print(f"Vulnerabilities confirmed: {vulnerabilities_found}")

    if vulnerabilities_found > 0:
        print("\nüö® CRITICAL: Template injection vulnerability CONFIRMED!")
        print("   The manual replacement approach is fundamentally insecure")
        return False
    else:
        print("\nüîç No obvious vulnerabilities found with current attack vectors")
        print("   But the approach is still theoretically vulnerable")
        return True

def test_edge_case_vulnerability():
    """Test edge cases that might reveal vulnerabilities."""

    print("\nüî¨ TESTING EDGE CASE VULNERABILITIES")
    print("=" * 45)

    # Test the exact sequence: sanitization -> replacement -> final check
    edge_cases = [
        # Case where sanitization removes characters that creates new dangerous patterns
        {
            "name": "Sanitization Creates Dangerous Boundaries",
            "inputs": ["act", "__import__('os')", "ion"],
            "template": "The {action}{component}{issue} system fails",
            "hypothesis": "Removal of dangerous import might create 'action' with system context"
        },

        # Case with template that has nested placeholders
        {
            "name": "Nested Template Boundary",
            "inputs": ["test", "component", "{action}"],
            "template": "System {action} fails on {component} with {issue}",
            "hypothesis": "Nested {action} might create new pattern"
        },

        # Case with multiple replacements affecting each other
        {
            "name": "Cross-Contamination",
            "inputs": ["{component}", "__import__('os')", "failure"],
            "template": "The {action} affects {component} causing {issue}",
            "hypothesis": "Action replacement might affect component processing"
        }
    ]

    for case in edge_cases:
        print(f"\nTesting: {case['name']}")
        print(f"Hypothesis: {case['hypothesis']}")

        try:
            result = _safe_hypothesis_template(
                case['inputs'][0],
                case['inputs'][1],
                case['inputs'][2],
                case['template']
            )
            print(f"Result: '{result}'")

            # Analyze the result for the expected vulnerability
            if "action" in result and "component" in result:
                print("‚ö†Ô∏è  Cross-contamination detected")
            elif "import" in result.lower():
                print("‚ö†Ô∏è  Import pattern detected")
            else:
                print("‚úÖ No obvious vulnerability")

        except Exception as e:
            print(f"Exception: {e}")

if __name__ == "__main__":
    print("Template Injection Vulnerability Discovery")
    print("Testing for actual exploitable vulnerabilities")
    print()

    # Test for actual vulnerabilities
    is_secure = demonstrate_actual_vulnerability()

    # Test edge cases
    test_edge_case_vulnerability()

    print("\n" + "=" * 60)
    print("üéØ FINAL VULNERABILITY ASSESSMENT")
    print("=" * 60)

    if not is_secure:
        print("üö® TEMPLATE INJECTION VULNERABILITY CONFIRMED!")
        print("   Immediate security fix required")
        sys.exit(1)
    else:
        print("üîç No confirmed vulnerabilities found")
        print("   However, manual replacement approach remains theoretically insecure")
        print("   Recommend implementing proper secure templating")
        sys.exit(0)